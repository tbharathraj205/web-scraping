# Web Article Scraper & Summarizer

A script that searches the web, collects article links, extracts text, and summarizes the information using the OpenAI API. All results are saved into a structured JSON file.

## âœ¨ How It Works

1. You enter a search term.

2. The script finds related web pages (via DuckDuckGo).

3. Text content is extracted from each page.

4. AI generates a clear, short summary.

5. Everything is saved to articles.json.

## ğŸš€ Features

- Web search using DuckDuckGo (ddgs)

- Automatic webpage text extraction with BeautifulSoup

- AI summaries generated using OpenAI

- Avoids duplicates and skips unreadable pages

- Saves results in clean JSON format

## ğŸ“‚ Project Structure
```
project-folder/
â”‚
â”œâ”€â”€ main.py           # Orchestrates search + scraping + summarization
â”œâ”€â”€ summarize.py      # Handles text extraction + OpenAI summary generation
â””â”€â”€ articles.json     # Output file created after running the script
```
ğŸ”§ Installation

Install required dependencies:

```
pip install ddgs requests beautifulsoup4 openai
```

### ğŸ”‘ API Key Setup

Open summarize.py and set your OpenAI API key:
```
openai.api_key = "your_api_key_here"

```
## â–¶ï¸ Usage

Run the script:
```
python main.py
```

You'll be prompted for:
```
Enter your search query:
How many results? (default 10):
```

Example:
```
Enter your search query: climate change news
How many results? (default 10): 5

```
The script will then:

- Search DuckDuckGo

- Extract article text

- Summarize each article

- Save everything into summarize.json

ğŸ“ Output Example (summarize.json)
```
[
  {
    "url": "https://example.com/article",
    "status": 200,
    "summary": "This article discusses the impact of climate change..."
  }
]
```

## âš  Notes

Some websites may block scraping or have unreadable content â€” these are automatically skipped.

Default summarization model is gpt-3.5-turbo. You can change the model in summarize.py.

